import torch
import numpy as np
import torchvision.transforms as transforms
import glob
import os
import PIL.Image


# è¾…åŠ©å‡½æ•°ï¼Œè§£æå½’ä¸€åŒ–åæ ‡
def get_x(path, width):
    return (float(int(path.split("_")[1])) * 224.0 / 640.0 - width/2) / (width/2)

def get_y(path, height):
    return ((224 - float(int(path.split("_")[2]))) - height/2) / (height/2)


# è‡ªå®šä¹‰ Dataset
class XYDataset(torch.utils.data.Dataset):
    def __init__(self, directory, random_hflips=False):
        self.directory = directory
        self.random_hflips = random_hflips
        self.image_paths = glob.glob(os.path.join(self.directory, '*.jpg'))
        self.color_jitter = transforms.ColorJitter(0.3, 0.3, 0.3, 0.3)

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image_path = self.image_paths[idx]
        image = PIL.Image.open(image_path)
        x = float(get_x(os.path.basename(image_path), 224))
        y = float(get_y(os.path.basename(image_path), 224))

        if self.random_hflips:
            if float(np.random.rand(1)) > 0.5:
                image = transforms.functional.hflip(image)
                x = -x

        image = self.color_jitter(image)
        image = transforms.functional.resize(image, (224, 224))
        image = transforms.functional.to_tensor(image)
        image = image.numpy().copy()
        image = torch.from_numpy(image)
        image = transforms.functional.normalize(image,
                                                [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        return image, torch.tensor([x, y]).float()


# è‡ªå®šä¹‰å°å‹ CNN
class SmallCNN(torch.nn.Module):
    def __init__(self):
        super(SmallCNN, self).__init__()
        self.features = torch.nn.Sequential(
            torch.nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2),
            torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2),
            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2)
        )
        self.classifier = torch.nn.Sequential(
            torch.nn.Flatten(),
            torch.nn.Linear(64 * 28 * 28, 512),
            torch.nn.ReLU(),
            torch.nn.Linear(512, 2)
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x


# åŠ è½½æ•°æ®
dataset = XYDataset('./image_dataset', random_hflips=False)

# åˆ’åˆ†è®­ç»ƒ / æµ‹è¯•é›†
test_percent = 0.4
num_test = int(test_percent * len(dataset))
train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - num_test, num_test])

test_loader = torch.utils.data.DataLoader(
    test_dataset,
    batch_size=16,
    shuffle=False,
    num_workers=0
)

# åŠ è½½ SmallCNN æ¨¡å‹
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = SmallCNN()
model.load_state_dict(torch.load('./best_line_follower_model_xy.pth', map_location=device))
model.to(device)
model.eval()

# æµ‹è¯•å¹¶è®¡ç®—å‡†ç¡®ç‡
threshold = 0.8707  # å¯¹åº”å½’ä¸€åŒ–é˜ˆå€¼
all_y_true = []
all_y_pred = []

with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device)
        outputs = model(images)

        y_true_batch = labels[:, 1].cpu().numpy()
        y_pred_batch = outputs[:, 1].cpu().numpy()

        all_y_true.append(y_true_batch)
        all_y_pred.append(y_pred_batch)

# æ•´åˆæ‰€æœ‰ batch
all_y_true = np.concatenate(all_y_true)
all_y_pred = np.concatenate(all_y_pred)

# ç”¨ all_y_true å’Œ all_y_pred æ¥ç®—
is_real_intersection = (all_y_true > threshold)
is_pred_intersection = (all_y_pred > threshold)

TP = np.sum(is_real_intersection & is_pred_intersection)
TN = np.sum(~is_real_intersection & ~is_pred_intersection)
FP = np.sum(~is_real_intersection & is_pred_intersection)
FN = np.sum(is_real_intersection & ~is_pred_intersection)

accuracy = (TP + TN) / (TP + TN + FP + FN)

# é¿å…é™¤ä»¥ 0
intersection_total = np.sum(is_real_intersection)
non_intersection_total = np.sum(~is_real_intersection)

if intersection_total > 0:
    recall_intersection = TP / intersection_total
else:
    recall_intersection = float('nan')

if non_intersection_total > 0:
    recall_non_intersection = TN / non_intersection_total
else:
    recall_non_intersection = float('nan')

# è¾“å‡º
print("\n========= ğŸ“Š ~å®Œæ•´æµ‹è¯•é›†è¯„ä¼°ç»“æœ ğŸ“Š =========")
print(f"âœ… æ€»ä½“è¯†åˆ«å‡†ç¡®ç‡ (Accuracy): {accuracy * 100:.2f}%")
print(f"âœ… è·¯å£è¯†åˆ«ç‡ (Recall for è·¯å£): {recall_intersection * 100:.2f}%")
print(f"âœ… éè·¯å£è¯†åˆ«ç‡ (Recall for éè·¯å£): {recall_non_intersection * 100:.2f}%")
print(f"âœ… æµ‹è¯•é›†ä¸­çœŸå®è·¯å£æ ·æœ¬æ¯”ä¾‹: {np.mean(is_real_intersection) * 100:.2f}%")
print(f"âœ… æµ‹è¯•é›†ä¸­çœŸå®éè·¯å£æ ·æœ¬æ¯”ä¾‹: {np.mean(~is_real_intersection) * 100:.2f}%")
print("\n--------- æ··æ·†çŸ©é˜µç»“æœ ---------")
print(f"True Positive (TP - è·¯å£è¯†åˆ«æˆè·¯å£): {TP}")
print(f"True Negative (TN - éè·¯å£è¯†åˆ«æˆéè·¯å£): {TN}")
print(f"False Positive (FP - éè·¯å£è¯†åˆ«æˆè·¯å£): {FP}")
print(f"False Negative (FN - è·¯å£è¯†åˆ«æˆéè·¯å£): {FN}")
print("===================================")
